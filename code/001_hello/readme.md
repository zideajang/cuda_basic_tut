


## 课程主题：CUDA "Hello World" 
### 第一次GPU编程体验
#### 授课对象

* 对并行计算和高性能计算感兴趣的初学者。
* 具备基本C语言编程经验，但不熟悉CUDA编程的学员。
* 希望了解GPU如何加速计算的基础概念。

#### 教学目标

学完本课程，学生将能够：

1.  理解CPU和GPU在程序执行中的角色分工。
2.  掌握CUDA编程中最基本的“核函数”概念。
3.  学会如何编写并调用一个简单的CUDA核函数。
4.  理解`__global__`关键字和执行配置`<<<>>>`的含义。
5.  了解`cudaDeviceSynchronize()`函数的作用。
6.  成功编译并运行第一个CUDA程序，看到CPU和GPU的输出。

#### 课程时长

10 分钟左右

#### 课程材料

* 安装了CUDA工具包 (CUDA Toolkit) 的开发环境 (包含NVIDIA显卡驱动、nvcc编译器)。
* 支持CUDA的NVIDIA GPU。
* 文本编辑器或IDE (如VS Code, Visual Studio等)。
* 本教案中提供的“Hello World”示例代码。

---

#### 课程内容

#### 1. 什么是CUDA？ 

* **引入：** 我们常用的CPU擅长处理串行任务，但对于大规模并行任务效率不高。想象一下，一个工厂里只有少数几个万能工人，而另一个工厂有成千上万个只负责简单任务的工人。哪个处理大规模生产更快？
* **概念：** **CUDA (Compute Unified Device Architecture)** 是NVIDIA推出的一种并行计算平台和编程模型，它允许开发者使用C/C++等语言直接在NVIDIA GPU上进行编程，利用GPU强大的并行处理能力来加速计算。
* **CPU vs. GPU：**
    * **CPU (Central Processing Unit)：** 核心少，每个核心功能强大，擅长复杂的逻辑控制和串行计算。好比工厂里的“管理层”，负责决策和协调。
    * **GPU (Graphics Processing Unit)：** 核心多（几百到几千个），每个核心功能相对简单，擅长执行大量重复且独立的计算任务。好比工厂里的“流水线工人”，负责大量简单的重复劳动。
* **并行计算：** 同时处理多个任务，而不是一个接一个地处理。GPU是天生的并行计算利器。

---

#### 2. CUDA编程模型基础：Host与Device

* **Host (主机)：** 指的是CPU及其系统内存。我们编写的C/C++代码通常在主机上执行。
* **Device (设备)：** 指的是GPU及其显存。CUDA核函数在设备上执行。
* **交互：** CPU负责启动GPU上的计算（调用核函数），以及处理GPU返回的结果。数据也需要在主机内存和显存之间传输。
* **代码中的体现：**
    * `printf("Hello from CPU\n");` 这行代码在**主机 (CPU)** 上执行。
    * 我们即将编写的 `kernel()` 函数将在**设备 (GPU)** 上执行。

---

#### 3. 编写第一个CUDA核函数

* **核函数 (Kernel Function) 概念：**
    * 是在GPU上执行的函数。
    * 由多个并行运行的线程共同执行。
    * 通过`__global__`关键字修饰。
* **`__global__` 关键字：**
    * 告诉编译器：这是一个可以在GPU上执行的函数。
    * 只能从CPU (Host) 端调用。
    * 通常返回类型是 `void`。
* **代码示例：**
    ```c
    __global__
    void kernel()
    {
        printf("Hello from GPU\n");
    }
    ```
    * 这是一个最简单的核函数，它只做一件事：在GPU上打印一条消息。

* **执行配置 `<<<gridDim, blockDim>>>`：**
    * 核函数调用时后面跟着的三个尖括号 `<<<>>>` 就是**执行配置**。
    * 它告诉CUDA运行时：这个核函数要启动多少个并行线程。
    * 第一个参数 `gridDim`：指定**网格 (Grid)** 的维度和大小。网格是所有块的集合。
    * 第二个参数 `blockDim`：指定**块 (Block)** 的维度和大小。块是线程的集合。
    * **本例中 `<<<1,1>>>` 的含义：**
        * 启动一个网格（`gridDim` = 1）。
        * 这个网格包含一个块（`blockDim` = 1）。
        * 这个块包含一个线程。
        * 所以 `kernel()` 函数只在一个GPU线程上执行。
* **代码示例：**
    ```c
    kernel<<<1,1>>>(); // 在CPU上调用核函数，并在GPU上以1个线程执行
    ```

---

#### 4. 同步与结果观察 

* **异步执行：** CPU调用核函数后，并不会等待GPU执行完毕，而是会立即执行后续的CPU代码。
* **`cudaDeviceSynchronize()` 函数：**
    * 强制CPU等待，直到所有之前提交到GPU的任务都完成。
    * 在本例中，它确保GPU上的 `printf` 有机会执行，并且在CPU程序结束前完成输出。
* **代码示例：**
    ```c
    cudaDeviceSynchronize(); // 强制CPU等待GPU任务完成
    ```
* **预期输出：**
    ```
    Hello from CPU
    Hello from GPU
    ```
    （顺序可能因系统而异，但两条消息都会出现）

---

#### 5. 编译与运行

* **编译命令：** 使用 `nvcc` 编译器来编译CUDA代码。
    * 打开终端或命令行。
    * 导航到保存 `.cu` 文件（CUDA源文件通常以`.cu`为后缀）的目录。
    * 编译命令：`nvcc your_file_name.cu -o your_executable_name`
        * 例如：`nvcc hello_world.cu -o hello`
* **运行命令：**
    * `./your_executable_name`
    * 例如：`./hello`
* **实践环节：**
    * 指导学生将代码保存为 `hello_world.cu`。
    * 带领学生执行编译和运行命令。
    * 观察输出结果，确认“Hello from CPU”和“Hello from GPU”都已显示。

---

#### 6. 总结与展望 

* **总结：** 我们成功编写并运行了第一个CUDA程序，实现了CPU和GPU的协同工作，并让GPU打印了“Hello World”。这是踏入并行计算世界的第一步。
* **未来：** 实际的CUDA编程会涉及更多并行线程、数据传输、线程间通信等复杂概念，但核心思想都是将任务分解给GPU的无数个线程并行处理。

---